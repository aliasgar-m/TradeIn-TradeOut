{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# TradeIn-TradeOut\n",
    "\n",
    "Predicting the closing price movements for hundreds of Nasdaq listed stocks using data from the order book and the closing auction of the stock."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f9a25276c6dff57d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from strictyaml import load, YAMLError, Map, Str\n",
    "from collections import OrderedDict\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn import neighbors\n",
    "from sklearn import ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Class that allows one to load and save datasets."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1668767598d2ac43"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class FileOperations:\n",
    "    @staticmethod\n",
    "    def load_raw_dataset(filepath: str) -> pd.DataFrame:\n",
    "        schema = {\n",
    "            \"stock_id\": \"Int64\",\n",
    "            \"date_id\": \"Int64\",\n",
    "            \"seconds_in_bucket\": \"Int64\",\n",
    "            \"imbalance_size\": \"float32\",\n",
    "            \"imbalance_buy_sell_flag\": \"float32\",\n",
    "            \"reference_price\": \"float32\",\n",
    "            \"matched_size\": \"float32\",\n",
    "            \"far_price\": \"float32\",\n",
    "            \"near_price\": \"float32\",\n",
    "            \"bid_price\": \"float32\",\n",
    "            \"bid_size\": \"float32\",\n",
    "            \"ask_price\": \"float32\",\n",
    "            \"ask_size\": \"float32\",\n",
    "            \"wap\": \"float32\",\n",
    "            \"target\": \"float32\",\n",
    "            \"time_id\": \"Int64\",\n",
    "            \"row_id\": \"string\"\n",
    "        }\n",
    "\n",
    "        return pd.read_csv(filepath, dtype=schema)\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def save_prep_dataset(df: pd.DataFrame, filepath: str) -> None:\n",
    "        df.to_csv(filepath)\n",
    "        return"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9b0fdf69ecf61d1e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Class that allows one to import Configuration Parameters from config.yaml"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cce265f2cd4b47e5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "try:\n",
    "    schema = Map({\n",
    "        \"inputDirectory\": Str(),\n",
    "        \"inputFile\": Str(),\n",
    "        \"outputDirectory\": Str(),\n",
    "        \"outputFile\": Str()\n",
    "    })\n",
    "\n",
    "    with open(\"./config.yaml\", \"r\") as file:\n",
    "        configDataMap: OrderedDict = load(yaml_string=file.read(), schema=schema).data\n",
    "    file.close()\n",
    "\n",
    "except YAMLError as error:\n",
    "    print(error)\n",
    "    exit()\n",
    "\n",
    "\n",
    "class ConfigReader:\n",
    "    def __init__(self):\n",
    "        self.inputDirectory = configDataMap.get(\"inputDirectory\")\n",
    "        self.inputFile = configDataMap.get(\"inputFile\")\n",
    "        self.outputDirectory = configDataMap.get(\"outputDirectory\")\n",
    "        self.outputFile = configDataMap.get(\"outputFile\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6b767b95628c1221"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Class that provides preprocessing functionality. This includes:\n",
    "1. Removing null values from specified columns.\n",
    "2. Filling null values with user specified values or the mean values.\n",
    "3. Get the number of null values per column."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "15df858ce15d9664"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Preprocess:\n",
    "    def __init__(self, df: pd.DataFrame):\n",
    "        self.df = df\n",
    "\n",
    "    def get_null_values_per_column(self):\n",
    "        print(self.df.isnull().sum())\n",
    "        return self\n",
    "\n",
    "    def remove_null_values(self, column: str):\n",
    "        self.df = self.df.dropna(subset=[column])\n",
    "        return self\n",
    "\n",
    "    def fill_null_values(self, column: list[str] = None, value: int | float = None, type_fill: str = None):\n",
    "        if type_fill is None:\n",
    "            self.df.loc[:, column] = self.df[column].fillna(value)\n",
    "            return self\n",
    "\n",
    "        elif type_fill == 'mean':\n",
    "            input_cols = [c for c in self.df.columns if c != \"row_id\"]\n",
    "            output_cols = [c for c in self.df.columns if c != \"row_id\"]\n",
    "\n",
    "            self.impute_columns(input_cols, output_cols)\n",
    "            return self\n",
    "\n",
    "    def impute_columns(self, input_cols, output_cols):\n",
    "        for input_col, output_col in zip(input_cols, output_cols):\n",
    "            mean_value = self.df[input_col].mean()\n",
    "\n",
    "            self.df.loc[:, output_col] = self.df[input_col].fillna(mean_value)\n",
    "        return self"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dfc306269debbbc7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Class that engineers new features from the dataset. These include:\n",
    "1. Spread: The gap between the Bid and Ask prices.\n",
    "2. Imbalance Ratio: Ratio of the imbalance size to the matched sizes.\n",
    "3. Volume: The total number of bid and sell sizes.\n",
    "4. Mid-Price: Middle value between the bid price and the ask size.\n",
    "5. Liquidity Imbalance: The ratio of the difference in the bid and ask size to the total volume.\n",
    "6. Match Ratio: The ratio of the matched size to the total volume.\n",
    "7. Minutes: The seconds in the bucket converted to minutes "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9cbfc269d7020bb2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class FeatureEngineer:\n",
    "    def __init__(self, df: pd.DataFrame) -> None:\n",
    "        self.df = df.copy()\n",
    "\n",
    "    def generate_spread(self):\n",
    "        self.df.loc[:, 'spread'] = self.df['bid_price'] - self.df['ask_price']\n",
    "        return self\n",
    "\n",
    "    def generate_imbalance_ratio(self):\n",
    "        self.df.loc[:, 'imbalance_ratio'] = self.df['imbalance_size'] / self.df['matched_size']\n",
    "        return self\n",
    "\n",
    "    def generate_volume(self):\n",
    "        self.df.loc[:, 'volume'] = self.df['bid_size'] + self.df['ask_size']\n",
    "        return self\n",
    "\n",
    "    def generate_mid_price(self):\n",
    "        self.df.loc[:, 'mid_price'] = (self.df['ask_price'] + self.df['bid_price']) / 2\n",
    "        return self\n",
    "\n",
    "    def liquidity_imbalance(self):\n",
    "        self.df.loc[:, 'liquidity_imbalance'] = ((self.df['bid_size'] - self.df['ask_size']) /\n",
    "                                                 (self.df['bid_size'] + self.df['ask_size']))\n",
    "        return self\n",
    "\n",
    "    def match_ratio(self):\n",
    "        self.df.loc[:, 'matched_ratio'] = self.df['matched_size'] / (self.df['bid_size'] + self.df['ask_size'])\n",
    "        return self\n",
    "\n",
    "    def generate_minutes(self):\n",
    "        self.df.loc[:, 'minutes'] = self.df['seconds_in_bucket'] // 60\n",
    "        return self"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3eb478b7381b679a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Class that splits the dataset into Training and Test datasets using the 80/20 rule.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "265a58186b60f3dc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def split_data(df: pd.DataFrame):\n",
    "    train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "    train_y = train_df['target']\n",
    "    train_x = train_df.drop('target', axis=1)\n",
    "\n",
    "    test_y = test_df['target']\n",
    "    test_x = test_df.drop('target', axis=1)\n",
    "\n",
    "    return train_x, train_y, test_x, test_y\n",
    "\n",
    "\n",
    "def to_pandas(iterator):\n",
    "    yield pd.DataFrame(iterator)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6ab8a979e6d975f5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Main program"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5e55f8f9cb1c0141"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fileOperator = FileOperations()\n",
    "configOperator = ConfigReader()\n",
    "\n",
    "rawDataFrame = fileOperator.load_raw_dataset(configOperator.inputDirectory + configOperator.inputFile)\n",
    "\n",
    "processedDataFrame = \\\n",
    "    Preprocess(rawDataFrame) \\\n",
    "        .get_null_values_per_column() \\\n",
    "        .remove_null_values('target') \\\n",
    "        .fill_null_values(['far_price', 'near_price'], 0.0) \\\n",
    "        .fill_null_values(type_fill=\"mean\") \\\n",
    "        .df\n",
    "\n",
    "processedDataFrame.loc[processedDataFrame['imbalance_buy_sell_flag'] == 0.0, 'imbalance_size'] = 0.0\n",
    "\n",
    "engineeredDataFrame = \\\n",
    "    FeatureEngineer(processedDataFrame) \\\n",
    "        .generate_spread() \\\n",
    "        .generate_imbalance_ratio() \\\n",
    "        .generate_volume() \\\n",
    "        .generate_mid_price() \\\n",
    "        .liquidity_imbalance() \\\n",
    "        .match_ratio() \\\n",
    "        .generate_minutes() \\\n",
    "        .df\n",
    "\n",
    "print(\"\\nRaw DataFrame Example Data\")\n",
    "print(rawDataFrame.head())\n",
    "\n",
    "print(\"\\nNull Values in Raw DataFrame\")\n",
    "Preprocess(rawDataFrame).get_null_values_per_column()\n",
    "\n",
    "print(\"\\nData Frame After Feature Engineering\")\n",
    "print(engineeredDataFrame.head())\n",
    "\n",
    "print(\"\\nNow splitting the dataset into Training and Test Sets based on a 80/20 split.\")\n",
    "trainX, trainY, crossValX, crossValY = split_data(engineeredDataFrame)\n",
    "\n",
    "\n",
    "print(\"Training the following Machine Learning Models:\")\n",
    "print(\"1. Linear Regression\")\n",
    "linearRegModel = linear_model.Ridge(alpha=.5)\n",
    "linearRegModel.fit(trainX, trainY)\n",
    "linearTarget = linearRegModel.predict(crossValX)\n",
    "lTError = mean_squared_error(crossValY, linearTarget)\n",
    "\n",
    "# print(\"2. Elastic Net\")\n",
    "# elasticNetModel = linear_model.ElasticNet(alpha=.5, tol=0.001)\n",
    "# elasticNetModel.fit(trainX, trainY)\n",
    "# elasticNetTarget = elasticNetModel.predict(crossValX)\n",
    "# eNTError = mean_squared_error(crossValY, elasticNetTarget)\n",
    "\n",
    "print(\"3. K Nearest Neighbors\")\n",
    "knnModel = neighbors.KNeighborsRegressor(n_neighbors=5, weights=\"uniform\", n_jobs=5)\n",
    "knnModel.fit(trainX, trainY)\n",
    "knnModelTarget = knnModel.predict(crossValX)\n",
    "kMTError = mean_squared_error(crossValY, knnModelTarget)\n",
    "\n",
    "print(\"4. Random Forest\")\n",
    "randomForestModel = ensemble.RandomForestRegressor(24, max_samples=0.7, n_jobs=5)\n",
    "randomForestModel.fit(trainX, trainY)\n",
    "randomForestTarget = randomForestModel.predict(crossValX)\n",
    "rFTError = mean_squared_error(crossValY, randomForestTarget)\n",
    "\n",
    "print(\"Here are the generated statistics for the tested algorithms on the cross validation set.\")\n",
    "print(\"MSE for Linear Regression:\", lTError)\n",
    "print(\"MSE for K Nearest Neighbors:\", kMTError)\n",
    "print(\"MSE for Random Forest:\", rFTError)\n",
    "\n",
    "# fileOperator.save_prep_dataset(engineeredDataFrame, configOperator.outputDirectory + configOperator.outputFile)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-17T14:19:24.389842981Z"
    }
   },
   "id": "c89575c2d9eb8394"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# References\n",
    "- https://www.kaggle.com/code/hrhuynguyen/eda-for-training-dataset\n",
    "- https://www.kaggle.com/code/yekenot/feature-elimination-by-catboost\n",
    "- https://www.kaggle.com/competitions/optiver-trading-at-the-close/discussion/453609\n",
    "- https://www.kaggle.com/code/sohier/optiver-2023-basic-submission-demo\n",
    "- https://www.kaggle.com/competitions/optiver-trading-at-the-close/discussion/443396\n",
    "- https://www.kaggle.com/code/zulqarnainali/explained-singel-model-optiver\n",
    "- https://www.kaggle.com/code/verracodeguacas/fold-cv\n",
    "- https://www.kaggle.com/code/cv13j0/optiver-ml-trading-at-the-close\n",
    "- https://www.kaggle.com/code/jirkaborovec/optiver-eda-pytorch-regression\n",
    "- https://www.kaggle.com/code/aniketkolte04/optiver-2023-eda-pytorch-lstm-attention-model\n",
    "- https://francescobranda.netlify.app/post/distributed_deep_learning/\n",
    "- https://github.com/maxpumperla/elephas#basic-spark-integration"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b8bd40795a59db59"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f913b408e2b27fec"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
